# AutoZap Enhancement Roadmap

This document tracks planned enhancements to make AutoZap production-ready and portfolio-impressive.

**Last Updated:** 2025-12-23

---

## ğŸ¯ Quick Wins (1-3 hours each, High Impact)

### 1. â­ Prometheus Metrics Endpoint
**Effort:** 2 hours | **Impact:** ğŸ”¥ğŸ”¥ğŸ”¥ | **Status:** Not Started

**What:**
Expose `/metrics` endpoint with Prometheus-formatted metrics.

**Metrics to Track:**
```go
// Counter metrics
workflow_executions_total{workflow="docker-cleanup", status="success|failed"}
workflow_action_executions_total{workflow="api-health", action="check-endpoint"}

// Gauge metrics
agent_active_workflows
agent_uptime_seconds

// Histogram metrics
workflow_execution_duration_seconds{workflow="postgres-backup"}
action_execution_duration_seconds{action="http-request"}

// Info metrics
workflow_last_execution_timestamp{workflow="ssl-monitor"}
workflow_info{workflow="docker-cleanup", trigger_type="cron", schedule="0 2 * * 0"}
```

**Implementation:**
```go
// Add prometheus/client_golang dependency
import "github.com/prometheus/client_golang/prometheus"

// Create metrics
var (
    workflowExecutions = prometheus.NewCounterVec(...)
    workflowDuration = prometheus.NewHistogramVec(...)
)

// Expose endpoint
http.Handle("/metrics", promhttp.Handler())
```

**Value:**
- Shows SRE/observability expertise
- Grafana dashboard integration
- Production monitoring capability

**Interview Topics:**
- Observability patterns
- Prometheus/Grafana ecosystem
- Production metrics design

---

### 2. â­ Health Endpoints
**Effort:** 1 hour | **Impact:** ğŸ”¥ğŸ”¥ğŸ”¥ | **Status:** Not Started

**What:**
Add HTTP endpoints for health checks and status.

**Endpoints:**
```bash
GET /health    # Liveness probe - returns 200 if agent running
GET /ready     # Readiness probe - returns 200 if workflows loaded
GET /status    # Returns JSON with workflow states
```

**Response Format:**
```json
{
  "status": "healthy",
  "uptime": "24h15m30s",
  "workflows": {
    "total": 7,
    "running": 7,
    "failed": 0
  },
  "workflows_detail": [
    {
      "name": "docker-cleanup",
      "status": "running",
      "last_execution": "2025-12-23T02:00:00Z",
      "next_execution": "2025-12-30T02:00:00Z"
    }
  ]
}
```

**Kubernetes Integration:**
```yaml
livenessProbe:
  httpGet:
    path: /health
    port: 8080
readinessProbe:
  httpGet:
    path: /ready
    port: 8080
```

**Value:**
- Kubernetes-ready deployment
- Platform engineering best practice
- Container orchestration support

---

### 3. Workflow Validation Command
**Effort:** 1 hour | **Impact:** ğŸ”¥ğŸ”¥ | **Status:** Not Started

**What:**
Add `validate` command to check workflow files before deployment.

**Usage:**
```bash
./autozap validate ./workflows/my-workflow.yaml
./autozap validate ./workflows/*.yaml
./autozap validate --strict  # Fail on warnings
```

**Checks:**
- âœ“ YAML syntax valid
- âœ“ All required fields present
- âœ“ Cron schedule syntax valid
- âœ“ File paths exist (for filewatch triggers)
- âœ“ URLs format valid (for HTTP actions)
- âœ“ No duplicate workflow names
- âœ“ Action types supported
- âœ“ Trigger types supported

**Output:**
```
Validating: workflows/docker-cleanup.yaml
âœ“ YAML syntax valid
âœ“ Workflow name present
âœ“ Trigger type 'cron' supported
âœ“ Schedule '0 2 * * 0' valid
âœ“ 6 actions validated
âœ“ Ready to deploy

Validating: workflows/broken.yaml
âœ— Missing required field: trigger.schedule
âœ— Invalid cron expression: '99 99 * * *'
âœ— Action type 'unknown' not supported

Validation failed: 1/2 workflows valid
```

**CI/CD Integration:**
```yaml
# .github/workflows/validate.yml
- name: Validate workflows
  run: ./autozap validate ./workflows/*.yaml
```

**Value:**
- CI/CD integration story
- Safety and testing
- DevOps maturity

---

### 4. Dry-Run Mode
**Effort:** 1 hour | **Impact:** ğŸ”¥ğŸ”¥ | **Status:** Not Started

**What:**
Run workflows without executing actions, showing what WOULD happen.

**Usage:**
```bash
./autozap run workflow.yaml --dry-run
./autozap agent --dry-run
```

**Output:**
```
[DRY RUN] Would start workflow: docker-cleanup
[DRY RUN] Trigger: cron (0 2 * * 0)
[DRY RUN] Would execute 6 actions:
  1. [bash] cleanup-stopped-containers
     Command: docker container prune -f
  2. [bash] cleanup-dangling-images
     Command: docker image prune -f
  ...
[DRY RUN] Next execution: 2025-12-30T02:00:00Z
```

**Implementation:**
- Add `--dry-run` flag
- Skip actual execution in triggers/actions
- Log what would be executed
- Useful for testing and debugging

**Value:**
- Safety feature
- Testing/debugging capability
- Production best practice

---

## ğŸ”¥ Medium Effort (4-8 hours each, Great Impact)

### 5. â­ Workflow State Persistence (SQLite)
**Effort:** 4 hours | **Impact:** ğŸ”¥ğŸ”¥ğŸ”¥ | **Status:** Not Started

**What:**
Store workflow execution history in SQLite database.

**Schema:**
```sql
CREATE TABLE workflow_executions (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    workflow_name TEXT NOT NULL,
    started_at TIMESTAMP NOT NULL,
    completed_at TIMESTAMP,
    status TEXT NOT NULL, -- running, success, failed
    error TEXT,
    duration_ms INTEGER,
    trigger_type TEXT,
    INDEX idx_workflow_started (workflow_name, started_at)
);

CREATE TABLE action_executions (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    workflow_execution_id INTEGER,
    action_name TEXT NOT NULL,
    action_type TEXT NOT NULL,
    started_at TIMESTAMP NOT NULL,
    completed_at TIMESTAMP,
    status TEXT NOT NULL,
    error TEXT,
    duration_ms INTEGER,
    output TEXT,
    FOREIGN KEY (workflow_execution_id) REFERENCES workflow_executions(id)
);
```

**New Commands:**
```bash
# Show execution history
./autozap history --workflow docker-cleanup --last 10

# Show statistics
./autozap stats --workflow api-health --last-7-days

# Show failures
./autozap failures --last-24h

# Export to CSV
./autozap export --workflow postgres-backup --csv
```

**Dashboard Queries:**
```sql
-- Success rate by workflow
SELECT workflow_name,
       COUNT(*) as total,
       SUM(CASE WHEN status='success' THEN 1 ELSE 0 END) as successful,
       ROUND(100.0 * SUM(CASE WHEN status='success' THEN 1 ELSE 0 END) / COUNT(*), 2) as success_rate
FROM workflow_executions
WHERE started_at > datetime('now', '-7 days')
GROUP BY workflow_name;

-- Average duration by workflow
SELECT workflow_name, AVG(duration_ms) / 1000.0 as avg_seconds
FROM workflow_executions
WHERE status = 'success'
GROUP BY workflow_name;
```

**Value:**
- Database skills demonstration
- Historical analysis
- Debugging capability
- Performance tracking

**Interview Topics:**
- Database design
- SQL queries
- State management
- Data retention policies

---

### 6. Template Variables in Workflows
**Effort:** 4 hours | **Impact:** ğŸ”¥ğŸ”¥ğŸ”¥ | **Status:** Not Started

**What:**
Support variable substitution in workflow definitions.

**Syntax:**
```yaml
name: "backup-database"
actions:
  - type: bash
    command: "pg_dump -U {{.DB_USER}} {{.DB_NAME}} > /backup/{{.DATE}}.sql"

  - type: http
    url: "{{.SLACK_WEBHOOK}}"
    body: '{"text": "Backup completed at {{.TIMESTAMP}}"}'
```

**Variable Sources:**
```bash
# 1. Environment variables
export DB_USER=postgres
export DB_NAME=mydb

# 2. Config file
# config.yaml
variables:
  slack_webhook: "https://hooks.slack.com/..."
  db_user: "postgres"

# 3. Runtime variables
DATE=$(date +%Y%m%d)
TIMESTAMP=$(date -u +"%Y-%m-%dT%H:%M:%SZ")

# 4. Previous action outputs
actions:
  - type: bash
    name: get-version
    command: "git describe --tags"
    save_output: VERSION

  - type: http
    body: '{"version": "{{.VERSION}}"}'
```

**Built-in Variables:**
```
{{.DATE}}           # 2025-12-23
{{.TIME}}           # 15:30:45
{{.TIMESTAMP}}      # 2025-12-23T15:30:45Z
{{.WORKFLOW_NAME}}  # Current workflow name
{{.HOSTNAME}}       # Current hostname
{{.USER}}           # Current user
```

**Implementation:**
- Use Go's `text/template` package
- Parse templates during workflow loading
- Substitute variables before execution
- Support nested variables

**Value:**
- Reusable workflows
- Configuration management
- Templating skills
- DRY principle

---

### 7. Retry Logic with Exponential Backoff
**Effort:** 3 hours | **Impact:** ğŸ”¥ğŸ”¥ğŸ”¥ | **Status:** Not Started

**What:**
Add retry capability to actions with configurable backoff.

**Configuration:**
```yaml
actions:
  - type: http
    name: call-flaky-api
    url: "https://api.example.com/endpoint"
    retry:
      max_attempts: 5
      backoff: exponential  # or: constant, linear
      initial_delay: 1s
      max_delay: 60s
      multiplier: 2
      retry_on:
        - timeout
        - status: [500, 502, 503, 504]
```

**Backoff Algorithms:**
```go
// Exponential: delay = initial * (multiplier ^ attempt)
// Attempt 1: 1s
// Attempt 2: 2s
// Attempt 3: 4s
// Attempt 4: 8s
// Attempt 5: 16s

// With jitter (recommended):
delay = (initial * multiplier^attempt) + random(0, jitter)
```

**Logging:**
```json
{
  "msg": "Action failed, retrying",
  "action": "call-flaky-api",
  "attempt": 1,
  "max_attempts": 5,
  "next_retry_in": "2s",
  "error": "connection timeout"
}
```

**Value:**
- Resilience patterns
- Production reliability
- Fault tolerance
- Network error handling

---

### 8. Webhook Trigger
**Effort:** 4 hours | **Impact:** ğŸ”¥ğŸ”¥ | **Status:** Not Started

**What:**
Add HTTP webhook trigger to start workflows via API calls.

**Configuration:**
```yaml
name: "deploy-notification"
trigger:
  type: webhook
  path: /webhooks/deploy
  method: POST
  secret: "${WEBHOOK_SECRET}"  # HMAC verification

actions:
  - type: http
    url: "{{.SLACK_WEBHOOK}}"
    body: '{"text": "Deployment triggered by {{.webhook.user}}"}'
```

**Usage:**
```bash
# Start webhook server
./autozap agent --http-port 8080

# Trigger workflow
curl -X POST http://localhost:8080/webhooks/deploy \
  -H "Content-Type: application/json" \
  -H "X-Webhook-Secret: secret123" \
  -d '{"user": "john", "version": "v1.2.3"}'
```

**Features:**
- HMAC signature verification
- Payload validation
- Rate limiting
- Webhook payload available as variables
- GitHub/GitLab webhook format support

**Implementation:**
```go
// Start HTTP server
go func() {
    http.HandleFunc("/webhooks/", webhookHandler)
    http.ListenAndServe(":8080", nil)
}()

// Verify signature
func verifySignature(body []byte, signature string, secret string) bool {
    mac := hmac.New(sha256.New, []byte(secret))
    mac.Write(body)
    expected := hex.EncodeToString(mac.Sum(nil))
    return hmac.Equal([]byte(signature), []byte(expected))
}
```

**Value:**
- HTTP server skills
- Authentication/security
- Event-driven integration
- API design

---

### 9. Simple Web Dashboard
**Effort:** 6 hours | **Impact:** ğŸ”¥ğŸ”¥ğŸ”¥ | **Status:** Not Started

**What:**
Web UI for monitoring and managing workflows.

**Features:**
- View all workflows and their status
- See last execution time and next scheduled time
- View real-time logs
- Manually trigger workflows
- View execution history
- See agent metrics

**Tech Stack Options:**

**Option A: Go Templates (Simple)**
```go
//go:embed templates/*
var templates embed.FS

func dashboardHandler(w http.ResponseWriter, r *http.Request) {
    tmpl := template.Must(template.ParseFS(templates, "templates/*.html"))
    tmpl.Execute(w, data)
}
```

**Option B: Static SPA (React/Vue)**
```
frontend/
â”œâ”€â”€ index.html
â”œâ”€â”€ app.js
â””â”€â”€ style.css

// Serve static files
http.FileServer(http.Dir("./frontend"))
```

**API Endpoints:**
```
GET  /api/workflows           # List all workflows
GET  /api/workflows/:name     # Get workflow details
POST /api/workflows/:name/trigger  # Trigger workflow
GET  /api/workflows/:name/logs     # Get logs
GET  /api/workflows/:name/history  # Get execution history
GET  /api/metrics             # Get metrics summary
```

**Screenshots:**
```
Dashboard:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AutoZap Agent Dashboard                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Status: Running | Uptime: 2d 5h         â”‚
â”‚ Workflows: 7 active | 0 failed          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Workflow              Status  Last Run  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ docker-cleanup        âœ“       2h ago    â”‚
â”‚ api-health-check      âœ“       5m ago    â”‚
â”‚ postgres-backup       âœ“       6h ago    â”‚
â”‚ ssl-cert-monitor      âœ“       12h ago   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Value:**
- Full-stack demonstration
- Visual demo for interviews
- User experience design
- Modern web development

---

## ğŸ’ Larger Features (8+ hours, Very Impressive)

### 10. Distributed Agent Mode with Leader Election
**Effort:** 12+ hours | **Impact:** ğŸ”¥ğŸ”¥ğŸ”¥ | **Status:** Not Started

**What:**
Run multiple AutoZap agents with coordination and leader election.

**Architecture:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  etcd/Consulâ”‚  â† Coordination service
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
   â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚        â”‚        â”‚        â”‚
â”Œâ”€â”€â–¼â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”
â”‚Agentâ”‚  â”‚Agentâ”‚  â”‚Agentâ”‚  â”‚Agentâ”‚  â† Multiple agents
â”‚  1  â”‚  â”‚  2  â”‚  â”‚  3  â”‚  â”‚  4  â”‚
â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜
```

**Features:**
- Leader election (one agent is leader)
- Distributed locking (prevent duplicate execution)
- Work distribution (load balancing workflows)
- Health monitoring (agents monitor each other)
- Failover (if leader dies, elect new one)

**Configuration:**
```yaml
agent:
  mode: distributed
  cluster:
    etcd_endpoints: ["localhost:2379"]
    lock_ttl: 30s
    election_timeout: 10s

workflows:
  docker-cleanup:
    execution_mode: singleton  # Only leader executes

  api-health-check:
    execution_mode: distributed  # All agents can execute
```

**Commands:**
```bash
# Start distributed agent
./autozap agent --distributed --etcd localhost:2379

# View cluster status
./autozap cluster status

# View leader
./autozap cluster leader
```

**Value:**
- Distributed systems expertise
- High availability
- Scalability patterns
- Senior/Staff level topic

**Interview Topics:**
- CAP theorem
- Consensus algorithms
- Distributed locking
- Leader election
- Split-brain scenarios

---

### 11. Plugin System for Custom Actions
**Effort:** 10+ hours | **Impact:** ğŸ”¥ğŸ”¥ | **Status:** Not Started

**What:**
Allow users to write custom action plugins in Go.

**Plugin Interface:**
```go
// plugins/interface.go
type ActionPlugin interface {
    Name() string
    Execute(ctx context.Context, config map[string]interface{}) error
    Validate(config map[string]interface{}) error
}
```

**Example Plugin:**
```go
// plugins/slack/slack.go
type SlackPlugin struct{}

func (p *SlackPlugin) Name() string {
    return "slack"
}

func (p *SlackPlugin) Execute(ctx context.Context, config map[string]interface{}) error {
    webhook := config["webhook"].(string)
    message := config["message"].(string)
    // Send to Slack
    return sendSlackMessage(webhook, message)
}
```

**Usage:**
```yaml
actions:
  - type: plugin
    plugin: slack
    config:
      webhook: "https://hooks.slack.com/..."
      message: "Deployment complete!"
```

**Plugin Discovery:**
```bash
# Install plugin
./autozap plugin install slack

# List plugins
./autozap plugin list

# Plugin directory
~/.autozap/plugins/
â”œâ”€â”€ slack.so
â”œâ”€â”€ pagerduty.so
â””â”€â”€ custom-action.so
```

**Value:**
- Extensibility design
- Plugin architecture
- Go plugin system
- Clean interfaces

---

### 12. Multi-Cloud Integration Actions
**Effort:** 8+ hours per cloud | **Impact:** ğŸ”¥ğŸ”¥ | **Status:** Not Started

**What:**
Built-in actions for cloud providers (AWS, GCP, Azure, Kubernetes).

**AWS Actions:**
```yaml
actions:
  - type: aws-s3
    action: upload
    bucket: backups
    key: "backup-{{.DATE}}.sql"
    file: /tmp/backup.sql

  - type: aws-lambda
    action: invoke
    function: process-data
    payload: '{"key": "value"}'

  - type: aws-ec2
    action: stop-instances
    filters:
      tag:Environment: dev
```

**Kubernetes Actions:**
```yaml
actions:
  - type: kubernetes
    action: restart
    deployment: api-server
    namespace: production

  - type: kubernetes
    action: scale
    deployment: worker
    replicas: 10

  - type: kubernetes
    action: apply
    manifest: ./k8s/deployment.yaml
```

**GCP Actions:**
```yaml
actions:
  - type: gcp-storage
    action: upload
    bucket: backups
    object: backup.sql

  - type: gcp-compute
    action: snapshot
    instance: prod-db-1
```

**Value:**
- Cloud-native expertise
- SDK integration
- Multi-cloud knowledge
- Infrastructure automation

---

## ğŸ“‹ Priority Matrix

| Feature | Effort | Portfolio Impact | Production Value | Priority |
|---------|--------|------------------|------------------|----------|
| **Prometheus Metrics** | 2h | ğŸ”¥ğŸ”¥ğŸ”¥ | ğŸ”¥ğŸ”¥ğŸ”¥ | **P0 - Do First** |
| **Health Endpoints** | 1h | ğŸ”¥ğŸ”¥ğŸ”¥ | ğŸ”¥ğŸ”¥ğŸ”¥ | **P0 - Do First** |
| **Validation Command** | 1h | ğŸ”¥ğŸ”¥ | ğŸ”¥ğŸ”¥ğŸ”¥ | **P1 - Do Next** |
| **Dry-Run Mode** | 1h | ğŸ”¥ğŸ”¥ | ğŸ”¥ğŸ”¥ğŸ”¥ | **P1 - Do Next** |
| **SQLite State** | 4h | ğŸ”¥ğŸ”¥ğŸ”¥ | ğŸ”¥ğŸ”¥ | **P1 - Weekend** |
| **Template Variables** | 4h | ğŸ”¥ğŸ”¥ | ğŸ”¥ğŸ”¥ğŸ”¥ | **P2 - Nice to Have** |
| **Web Dashboard** | 6h | ğŸ”¥ğŸ”¥ğŸ”¥ | ğŸ”¥ğŸ”¥ | **P2 - Weekend** |
| **Webhook Trigger** | 4h | ğŸ”¥ğŸ”¥ | ğŸ”¥ğŸ”¥ğŸ”¥ | **P2 - Nice to Have** |
| **Retry Logic** | 3h | ğŸ”¥ğŸ”¥ | ğŸ”¥ğŸ”¥ğŸ”¥ | **P2 - Nice to Have** |
| **Distributed Mode** | 12h+ | ğŸ”¥ğŸ”¥ğŸ”¥ | ğŸ”¥ | **P3 - Advanced** |
| **Plugin System** | 10h+ | ğŸ”¥ğŸ”¥ | ğŸ”¥ğŸ”¥ | **P3 - Advanced** |
| **Cloud Actions** | 8h+ | ğŸ”¥ğŸ”¥ | ğŸ”¥ğŸ”¥ | **P3 - Advanced** |

---

## ğŸ¯ Recommended Implementation Order

### **Phase 1: Observability (One Weekend - 4 hours)**
- [ ] Prometheus metrics endpoint
- [ ] Health/Ready/Status endpoints
- [ ] Workflow validation command
- [ ] Dry-run mode

**Result:** Production-grade observability

### **Phase 2: Persistence & History (One Weekend - 8 hours)**
- [ ] SQLite execution history
- [ ] Query commands (history, stats, failures)
- [ ] Simple web dashboard

**Result:** Full observability with UI

### **Phase 3: Enhanced Workflows (Optional)**
- [ ] Template variables
- [ ] Retry logic with backoff
- [ ] Webhook trigger

**Result:** Feature-complete automation platform

### **Phase 4: Advanced (Staff Engineer Level)**
- [ ] Distributed agent mode
- [ ] Plugin system
- [ ] Multi-cloud actions

**Result:** Enterprise-grade platform

---

## ğŸ“ Implementation Notes

### Testing Strategy
- Unit tests for new features
- Integration tests for HTTP endpoints
- Mock cloud SDKs for testing
- Benchmark tests for performance

### Documentation Updates
- Update README for each feature
- Add examples to workflows/
- Create ARCHITECTURE.md
- Write blog posts for major features

### LinkedIn Updates
- Post #3: Observability features (Prometheus + health endpoints)
- Post #4: State persistence and web UI
- Post #5: Distributed mode (if implemented)

---

## ğŸ¤ Contributing

These enhancements are open for community contribution. If you want to implement any of these features, please:

1. Create an issue first
2. Discuss the approach
3. Submit a PR with tests
4. Update documentation

---

**Note:** This roadmap is flexible. Priorities may change based on user feedback and job market requirements.
